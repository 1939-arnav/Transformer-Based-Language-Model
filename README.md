#  Transformer Script Writing Assistant

A PyTorch-based Transformer model trained on Shakespearean text to generate stylized dialogue and monologues — ideal for creative writing, theatrical scripts, or educational tools.

This project explores how attention-based architectures can be applied to assist script writing. The model is built completely from scratch using PyTorch and trained on the Tiny Shakespeare corpus. It uses subword-level tokenization (Byte-Pair Encoding) to learn expressive language patterns from a limited dataset.

The result is a compact, efficient language model capable of generating fluent, dramatic-style text that mimics Shakespearean language — showcasing how Transformers can be applied in creative and educational NLP tasks.

---

##  Features

- Transformer architecture inspired by the *Attention Is All You Need* paper
- Subword-level tokenization using **Byte-Pair Encoding (BPE)**
- Trained on the **Tiny Shakespeare** corpus (~1MB)
- Generates stylistically consistent Shakespearean text
- Includes both:
  - A clean Python script (`.py`) for training and generation
  - A full Jupyter notebook with theoretical explanation and implementation

---

##  Files

| File                                 | Description                                      |
|--------------------------------------|--------------------------------------------------|
| `transformer_script_writer.py`       | Final training + generation script               |
| `TransformerScriptWriter_Explained.ipynb` | Full notebook with theory + experiments     |
| `input.txt`                          | Training data (Tiny Shakespeare dataset)         |
| `output.txt`                         | Sample output generated by the model             |
| `requirements.txt`                   | Required packages for training and generation    |
| `README.md`                          | This file                                        |

---
